{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0       1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1       2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2       3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3       4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4       5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "..    ...         ...      ...          ...      ...    ...   ...      ...   \n",
      "995   996          50       RL         51.0     4712   Pave   NaN      IR1   \n",
      "996   997          20       RL          NaN    10659   Pave   NaN      IR1   \n",
      "997   998          20       RL          NaN    11717   Pave   NaN      IR1   \n",
      "998   999          30       RM         60.0     9786   Pave   NaN      Reg   \n",
      "999  1000          20       RL         64.0     6762   Pave   NaN      Reg   \n",
      "\n",
      "    LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
      "0           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "1           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "2           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "3           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "4           Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "..          ...       ...  ...      ...    ...    ...         ...     ...   \n",
      "995         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
      "996         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "997         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "998         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "999         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
      "\n",
      "    MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0        2   2008        WD         Normal     208500  \n",
      "1        5   2007        WD         Normal     181500  \n",
      "2        9   2008        WD         Normal     223500  \n",
      "3        2   2006        WD        Abnorml     140000  \n",
      "4       12   2008        WD         Normal     250000  \n",
      "..     ...    ...       ...            ...        ...  \n",
      "995      8   2006        WD        Abnorml     121600  \n",
      "996      1   2006       COD         Normal     136500  \n",
      "997      2   2009        WD         Normal     185000  \n",
      "998      5   2006        WD         Normal      91000  \n",
      "999      2   2010        WD         Normal     206000  \n",
      "\n",
      "[1000 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Load the dataset\n",
    "# -----------------------------\n",
    "# Replace 'house_prices.csv' with the path to your dataset.\n",
    "data = pd.read_csv('train.csv')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Id  MSSubClass  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0       1          60     8450            7            5       2003   \n",
      "1       2          20     9600            6            8       1976   \n",
      "2       3          60    11250            7            5       2001   \n",
      "3       4          70     9550            7            5       1915   \n",
      "4       5          60    14260            8            5       2000   \n",
      "..    ...         ...      ...          ...          ...        ...   \n",
      "995   996          50     4712            4            7       1946   \n",
      "996   997          20    10659            5            6       1961   \n",
      "997   998          20    11717            6            6       1970   \n",
      "998   999          30     9786            3            4       1922   \n",
      "999  1000          20     6762            7            5       2006   \n",
      "\n",
      "     YearRemodAdd  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  SaleType_ConLI  \\\n",
      "0            2003         706           0        150  ...               0   \n",
      "1            1976         978           0        284  ...               0   \n",
      "2            2002         486           0        434  ...               0   \n",
      "3            1970         216           0        540  ...               0   \n",
      "4            2000         655           0        490  ...               0   \n",
      "..            ...         ...         ...        ...  ...             ...   \n",
      "995          1950         384           0        363  ...               0   \n",
      "996          1961         915           0        135  ...               0   \n",
      "997          1970           0           0       1442  ...               0   \n",
      "998          1950           0           0       1007  ...               0   \n",
      "999          2006         686           0        501  ...               0   \n",
      "\n",
      "     SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
      "0                 0             0             0            1   \n",
      "1                 0             0             0            1   \n",
      "2                 0             0             0            1   \n",
      "3                 0             0             0            1   \n",
      "4                 0             0             0            1   \n",
      "..              ...           ...           ...          ...   \n",
      "995               0             0             0            1   \n",
      "996               0             0             0            0   \n",
      "997               0             0             0            1   \n",
      "998               0             0             0            1   \n",
      "999               0             0             0            1   \n",
      "\n",
      "     SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "0                        0                     0                     0   \n",
      "1                        0                     0                     0   \n",
      "2                        0                     0                     0   \n",
      "3                        0                     0                     0   \n",
      "4                        0                     0                     0   \n",
      "..                     ...                   ...                   ...   \n",
      "995                      0                     0                     0   \n",
      "996                      0                     0                     0   \n",
      "997                      0                     0                     0   \n",
      "998                      0                     0                     0   \n",
      "999                      0                     0                     0   \n",
      "\n",
      "     SaleCondition_Normal  SaleCondition_Partial  \n",
      "0                       1                      0  \n",
      "1                       1                      0  \n",
      "2                       1                      0  \n",
      "3                       0                      0  \n",
      "4                       1                      0  \n",
      "..                    ...                    ...  \n",
      "995                     0                      0  \n",
      "996                     1                      0  \n",
      "997                     1                      0  \n",
      "998                     1                      0  \n",
      "999                     1                      0  \n",
      "\n",
      "[1000 rows x 229 columns]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Data Cleaning\n",
    "# -----------------------------\n",
    "\n",
    "target = 'SalePrice'\n",
    "\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Convert any boolean columns to integer (0 or 1)\n",
    "data = data.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "\n",
    "# Select only numeric columns that have no missing data.\n",
    "#numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "clean_numeric_cols = [col for col in data if data[col].isna().sum() == 0]\n",
    "data_clean = data[clean_numeric_cols]\n",
    "\n",
    "\n",
    "# Ensure that the target column 'price' is present.\n",
    "if 'SalePrice' not in data_clean.columns:\n",
    "    raise ValueError(\"The target column 'price' is not present in the complete numeric data.\")\n",
    "\n",
    "\n",
    "print(data_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All features sorted by correlation with SalePrice:\n",
      "OverallQual        0.797666\n",
      "GrLivArea          0.734997\n",
      "GarageCars         0.658204\n",
      "GarageArea         0.647953\n",
      "TotalBsmtSF        0.642127\n",
      "                     ...   \n",
      "Condition1_RRNe    0.004722\n",
      "Heating_GasW       0.000977\n",
      "RoofMatl_Metal     0.000901\n",
      "PoolQC_Fa          0.000506\n",
      "BsmtFinSF2         0.000359\n",
      "Name: SalePrice, Length: 228, dtype: float64\n",
      "Selected top 15 features: ['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'ExterQual_TA', 'TotRmsAbvGrd', 'FullBath', 'KitchenQual_TA', 'YearBuilt', 'YearRemodAdd', 'Foundation_PConc', 'Fireplaces', 'BsmtQual_TA', 'Neighborhood_NridgHt', 'ExterQual_Gd', 'BsmtFinType1_GLQ', 'GarageFinish_Unf', 'BsmtFinSF1']\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 3. Feature Selection\n",
    "# -----------------------------\n",
    "# Compute the correlation matrix using only the cleaned numeric data.\n",
    "corr_matrix = data_clean.corr()\n",
    "\n",
    "# Compute absolute correlations of features with the target and drop the target itself.\n",
    "target_corr = corr_matrix['SalePrice'].drop('SalePrice').abs().sort_values(ascending=False)\n",
    "\n",
    "# Print all features with their correlation values\n",
    "print(\"All features sorted by correlation with SalePrice:\")\n",
    "print(target_corr)\n",
    "target_corr.to_csv('target_corr.csv')\n",
    "\n",
    "# Select only the top 4 features with the highest correlation with 'SalesPrice'\n",
    "top15_features = target_corr.head(20).index\n",
    "print(\"Selected top 15 features:\", list(top15_features))\n",
    "\n",
    "train_columns = data_clean.drop(columns=[target]).columns\n",
    "\n",
    "# Define input features (X) and target variable (y).\n",
    "X = data_clean[top15_features].values\n",
    "y = data_clean['SalePrice'].values.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 4. Data Preprocessing\n",
    "# -----------------------------\n",
    "# Split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features to improve training stability.\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy arrays to PyTorch tensors.\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset and DataLoader for batch processing.\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------\n",
    "# 5. Define the Neural Network Model\n",
    "# -----------------------------\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)  # Output layer for regression\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HousePriceModel(input_dim=X_train.shape[1]).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 35640258396.1600\n",
      "Epoch [20/1000], Loss: 13182327050.2400\n",
      "Epoch [30/1000], Loss: 6063930979.8400\n",
      "Epoch [40/1000], Loss: 4980816424.9600\n",
      "Epoch [50/1000], Loss: 4209443287.0400\n",
      "Epoch [60/1000], Loss: 3588340894.7200\n",
      "Epoch [70/1000], Loss: 3113222735.3600\n",
      "Epoch [80/1000], Loss: 2774982913.2800\n",
      "Epoch [90/1000], Loss: 2526361007.3600\n",
      "Epoch [100/1000], Loss: 2344245689.6000\n",
      "Epoch [110/1000], Loss: 2193129515.5200\n",
      "Epoch [120/1000], Loss: 2064111947.5200\n",
      "Epoch [130/1000], Loss: 1954554814.7200\n",
      "Epoch [140/1000], Loss: 1857810864.6400\n",
      "Epoch [150/1000], Loss: 1769540798.7200\n",
      "Epoch [160/1000], Loss: 1682837222.4000\n",
      "Epoch [170/1000], Loss: 1606826398.0800\n",
      "Epoch [180/1000], Loss: 1536684347.8400\n",
      "Epoch [190/1000], Loss: 1475659985.9200\n",
      "Epoch [200/1000], Loss: 1413742528.0000\n",
      "Epoch [210/1000], Loss: 1359493647.3600\n",
      "Epoch [220/1000], Loss: 1309110744.3200\n",
      "Epoch [230/1000], Loss: 1271732599.0400\n",
      "Epoch [240/1000], Loss: 1224923363.2000\n",
      "Epoch [250/1000], Loss: 1187760486.4000\n",
      "Epoch [260/1000], Loss: 1158647567.3600\n",
      "Epoch [270/1000], Loss: 1128536314.2400\n",
      "Epoch [280/1000], Loss: 1105747679.6800\n",
      "Epoch [290/1000], Loss: 1083037240.3200\n",
      "Epoch [300/1000], Loss: 1063083071.3600\n",
      "Epoch [310/1000], Loss: 1047329292.1600\n",
      "Epoch [320/1000], Loss: 1033856476.8000\n",
      "Epoch [330/1000], Loss: 1017036684.4800\n",
      "Epoch [340/1000], Loss: 1005139568.0000\n",
      "Epoch [350/1000], Loss: 995307073.1200\n",
      "Epoch [360/1000], Loss: 983853043.8400\n",
      "Epoch [370/1000], Loss: 974205410.8800\n",
      "Epoch [380/1000], Loss: 966864610.8800\n",
      "Epoch [390/1000], Loss: 960119902.0800\n",
      "Epoch [400/1000], Loss: 951127600.6400\n",
      "Epoch [410/1000], Loss: 945849409.6000\n",
      "Epoch [420/1000], Loss: 939844531.5200\n",
      "Epoch [430/1000], Loss: 933192754.8800\n",
      "Epoch [440/1000], Loss: 927785253.9200\n",
      "Epoch [450/1000], Loss: 924085657.9200\n",
      "Epoch [460/1000], Loss: 919178501.1200\n",
      "Epoch [470/1000], Loss: 914042340.6400\n",
      "Epoch [480/1000], Loss: 910796828.4800\n",
      "Epoch [490/1000], Loss: 907161083.3600\n",
      "Epoch [500/1000], Loss: 908197421.4400\n",
      "Epoch [510/1000], Loss: 898773943.0400\n",
      "Epoch [520/1000], Loss: 896605142.7200\n",
      "Epoch [530/1000], Loss: 896799227.2000\n",
      "Epoch [540/1000], Loss: 888876340.8000\n",
      "Epoch [550/1000], Loss: 887156222.7200\n",
      "Epoch [560/1000], Loss: 884247467.8400\n",
      "Epoch [570/1000], Loss: 880891781.7600\n",
      "Epoch [580/1000], Loss: 878760336.6400\n",
      "Epoch [590/1000], Loss: 877143955.5200\n",
      "Epoch [600/1000], Loss: 874998289.2800\n",
      "Epoch [610/1000], Loss: 876919560.1600\n",
      "Epoch [620/1000], Loss: 871311650.8800\n",
      "Epoch [630/1000], Loss: 871377854.4000\n",
      "Epoch [640/1000], Loss: 864966547.5200\n",
      "Epoch [650/1000], Loss: 862901897.2800\n",
      "Epoch [660/1000], Loss: 864429320.3200\n",
      "Epoch [670/1000], Loss: 859488550.5600\n",
      "Epoch [680/1000], Loss: 857677601.9200\n",
      "Epoch [690/1000], Loss: 853349631.5200\n",
      "Epoch [700/1000], Loss: 854153920.3200\n",
      "Epoch [710/1000], Loss: 849627056.0000\n",
      "Epoch [720/1000], Loss: 848490811.2000\n",
      "Epoch [730/1000], Loss: 846508852.1600\n",
      "Epoch [740/1000], Loss: 846208927.3600\n",
      "Epoch [750/1000], Loss: 845400043.2000\n",
      "Epoch [760/1000], Loss: 840520918.7200\n",
      "Epoch [770/1000], Loss: 841562003.5200\n",
      "Epoch [780/1000], Loss: 839081557.7600\n",
      "Epoch [790/1000], Loss: 839229211.8400\n",
      "Epoch [800/1000], Loss: 837371909.7600\n",
      "Epoch [810/1000], Loss: 833735743.3600\n",
      "Epoch [820/1000], Loss: 832365898.0800\n",
      "Epoch [830/1000], Loss: 834742144.6400\n",
      "Epoch [840/1000], Loss: 827718856.6400\n",
      "Epoch [850/1000], Loss: 827857131.5200\n",
      "Epoch [860/1000], Loss: 825624483.3600\n",
      "Epoch [870/1000], Loss: 826320588.3200\n",
      "Epoch [880/1000], Loss: 823557966.4000\n",
      "Epoch [890/1000], Loss: 820476449.1200\n",
      "Epoch [900/1000], Loss: 818852594.2400\n",
      "Epoch [910/1000], Loss: 818542888.8000\n",
      "Epoch [920/1000], Loss: 815980753.2800\n",
      "Epoch [930/1000], Loss: 819665531.2000\n",
      "Epoch [940/1000], Loss: 815112231.6800\n",
      "Epoch [950/1000], Loss: 812031605.1200\n",
      "Epoch [960/1000], Loss: 814224070.7200\n",
      "Epoch [970/1000], Loss: 811398961.6000\n",
      "Epoch [980/1000], Loss: 807497284.8000\n",
      "Epoch [990/1000], Loss: 808554072.6400\n",
      "Epoch [1000/1000], Loss: 806042762.2400\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 6. Set Up Loss Function and Optimizer\n",
    "# -----------------------------\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Train the Model\n",
    "# -----------------------------\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error: 697186304.0\n",
      "Predictions (NumPy): [[157803.78 ]\n",
      " [251705.22 ]\n",
      " [114728.57 ]\n",
      " [191357.72 ]\n",
      " [138121.34 ]\n",
      " [294526.5  ]\n",
      " [130679.984]\n",
      " [141683.94 ]\n",
      " [225542.16 ]\n",
      " [137784.5  ]\n",
      " [160974.56 ]\n",
      " [104454.74 ]\n",
      " [ 65842.42 ]\n",
      " [190606.75 ]\n",
      " [259168.58 ]\n",
      " [132805.62 ]\n",
      " [213462.4  ]\n",
      " [117348.14 ]\n",
      " [115642.28 ]\n",
      " [207971.25 ]\n",
      " [230617.75 ]\n",
      " [229648.12 ]\n",
      " [125788.95 ]\n",
      " [430898.66 ]\n",
      " [ 94881.234]\n",
      " [118616.266]\n",
      " [169684.28 ]\n",
      " [131577.97 ]\n",
      " [188999.03 ]\n",
      " [306831.62 ]\n",
      " [132027.42 ]\n",
      " [198798.34 ]\n",
      " [260635.06 ]\n",
      " [114438.67 ]\n",
      " [184652.66 ]\n",
      " [146466.92 ]\n",
      " [157878.58 ]\n",
      " [120098.48 ]\n",
      " [150393.3  ]\n",
      " [119956.61 ]\n",
      " [173235.1  ]\n",
      " [227721.3  ]\n",
      " [119589.15 ]\n",
      " [172981.38 ]\n",
      " [139843.94 ]\n",
      " [100746.484]\n",
      " [193384.38 ]\n",
      " [121923.88 ]\n",
      " [130362.84 ]\n",
      " [119441.97 ]\n",
      " [151142.44 ]\n",
      " [111245.516]\n",
      " [319371.25 ]\n",
      " [163547.53 ]\n",
      " [139055.34 ]\n",
      " [ 91849.43 ]\n",
      " [111924.875]\n",
      " [127766.375]\n",
      " [214560.02 ]\n",
      " [186551.5  ]\n",
      " [121724.06 ]\n",
      " [126412.734]\n",
      " [225347.28 ]\n",
      " [149606.8  ]\n",
      " [233284.   ]\n",
      " [295916.97 ]\n",
      " [178140.16 ]\n",
      " [261382.53 ]\n",
      " [320825.7  ]\n",
      " [154674.67 ]\n",
      " [ 97330.11 ]\n",
      " [130388.68 ]\n",
      " [195590.78 ]\n",
      " [135463.72 ]\n",
      " [145120.62 ]\n",
      " [126609.39 ]\n",
      " [196088.33 ]\n",
      " [ 86457.45 ]\n",
      " [ 98415.85 ]\n",
      " [105946.97 ]\n",
      " [128138.4  ]\n",
      " [264345.5  ]\n",
      " [153754.94 ]\n",
      " [227249.1  ]\n",
      " [305619.75 ]\n",
      " [127214.305]\n",
      " [ 99050.42 ]\n",
      " [147719.34 ]\n",
      " [291678.4  ]\n",
      " [143400.81 ]\n",
      " [208907.16 ]\n",
      " [208861.84 ]\n",
      " [165753.31 ]\n",
      " [226237.17 ]\n",
      " [238953.9  ]\n",
      " [106099.695]\n",
      " [228972.08 ]\n",
      " [ 88279.71 ]\n",
      " [140366.62 ]\n",
      " [ 91783.97 ]\n",
      " [188544.62 ]\n",
      " [218988.23 ]\n",
      " [195510.88 ]\n",
      " [198333.88 ]\n",
      " [295648.44 ]\n",
      " [321763.88 ]\n",
      " [285084.53 ]\n",
      " [164308.84 ]\n",
      " [198789.72 ]\n",
      " [125190.49 ]\n",
      " [ 93435.9  ]\n",
      " [133992.34 ]\n",
      " [124157.914]\n",
      " [122251.25 ]\n",
      " [167182.19 ]\n",
      " [130137.96 ]\n",
      " [116218.414]\n",
      " [107643.695]\n",
      " [191789.08 ]\n",
      " [202405.61 ]\n",
      " [136292.69 ]\n",
      " [145175.72 ]\n",
      " [124559.92 ]\n",
      " [163171.34 ]\n",
      " [201523.61 ]\n",
      " [205701.03 ]\n",
      " [342682.12 ]\n",
      " [157515.92 ]\n",
      " [127565.1  ]\n",
      " [188167.38 ]\n",
      " [158440.16 ]\n",
      " [154991.78 ]\n",
      " [187442.27 ]\n",
      " [104113.72 ]\n",
      " [300139.88 ]\n",
      " [165086.86 ]\n",
      " [149261.86 ]\n",
      " [139445.62 ]\n",
      " [278217.44 ]\n",
      " [196695.94 ]\n",
      " [119647.375]\n",
      " [141634.03 ]\n",
      " [157471.5  ]\n",
      " [191888.6  ]\n",
      " [145410.5  ]\n",
      " [165615.45 ]\n",
      " [170431.33 ]\n",
      " [256251.97 ]\n",
      " [198496.36 ]\n",
      " [348536.3  ]\n",
      " [139487.1  ]\n",
      " [235891.03 ]\n",
      " [213358.69 ]\n",
      " [186709.78 ]\n",
      " [237931.53 ]\n",
      " [117633.266]\n",
      " [400868.28 ]\n",
      " [111117.36 ]\n",
      " [177653.53 ]\n",
      " [116097.086]\n",
      " [318710.1  ]\n",
      " [154274.73 ]\n",
      " [ 91816.51 ]\n",
      " [193408.28 ]\n",
      " [140742.4  ]\n",
      " [153466.06 ]\n",
      " [148838.69 ]\n",
      " [193937.53 ]\n",
      " [156556.62 ]\n",
      " [177494.4  ]\n",
      " [125666.17 ]\n",
      " [120244.625]\n",
      " [148631.16 ]\n",
      " [187321.19 ]\n",
      " [136760.03 ]\n",
      " [134752.89 ]\n",
      " [136897.16 ]\n",
      " [101115.62 ]\n",
      " [200692.84 ]\n",
      " [103201.27 ]\n",
      " [105304.81 ]\n",
      " [174288.73 ]\n",
      " [289272.4  ]\n",
      " [119624.35 ]\n",
      " [219305.2  ]\n",
      " [215632.6  ]\n",
      " [158488.55 ]\n",
      " [124800.46 ]\n",
      " [146098.44 ]\n",
      " [103630.375]\n",
      " [203784.5  ]\n",
      " [158403.5  ]\n",
      " [119622.305]\n",
      " [308907.94 ]\n",
      " [148016.69 ]\n",
      " [290331.25 ]\n",
      " [350650.38 ]\n",
      " [236713.58 ]\n",
      " [132083.69 ]\n",
      " [134914.62 ]]\n",
      "Test MSE (scikit-learn): 697186304.0\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluate the Model\n",
    "# -----------------------------\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor.to(device))\n",
    "    test_loss = criterion(predictions, y_test_tensor.to(device)).item()\n",
    "    print(\"Test Mean Squared Error:\", test_loss)\n",
    "\n",
    "    # Convert predictions to NumPy array and print\n",
    "    predictions_np = predictions.cpu().numpy()\n",
    "    print(\"Predictions (NumPy):\", predictions_np)\n",
    "\n",
    "# Optionally, to evaluate using scikit-learn's MSE:\n",
    "mse = mean_squared_error(y_test, predictions_np)\n",
    "print(\"Test MSE (scikit-learn):\", mse)\n",
    "#Test Mean Squared Error: 935741376.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submission Preview:\n",
      "     ID      SALEPRICE\n",
      "0  1001   87043.984375\n",
      "1  1002   81143.265625\n",
      "2  1003  257956.968750\n",
      "3  1004  150092.390625\n",
      "4  1005  204407.328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the test.csv file (which lacks SalePrice but includes an 'Id' column)\n",
    "test_df = pd.read_csv('test.csv')\n",
    "ids = test_df['Id']\n",
    "\n",
    "# One-hot encode the test data using the same categorical columns as before\n",
    "#test_encoded = pd.get_dummies(test_df, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "data = pd.get_dummies(test_df, drop_first=True)\n",
    "# Convert any boolean columns to integer (0 or 1)\n",
    "data = data.apply(lambda col: col.astype(int) if col.dtype == 'bool' else col)\n",
    "\n",
    "# Reindex to match the training features\n",
    "data = data.reindex(columns=train_columns, fill_value=0)\n",
    "data = data[top15_features]  # Select the same top features\n",
    "data = data.astype(float)\n",
    "X_test_new = scaler.transform(data)\n",
    "\n",
    "X_test_tensor_new = torch.tensor(X_test_new, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor_new.to(device))\n",
    "    test_predictions_np = test_predictions.cpu().numpy()\n",
    "\n",
    "# Inverse transform predictions to get SalePrice in the original scale.\n",
    "#test_predictions_unscaled = scaler_y.inverse_transform(test_predictions_np)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': ids.astype(int),\n",
    "    'SALEPRICE': test_predictions_np.flatten().astype(float)\n",
    "})\n",
    "\n",
    "\n",
    "print(\"\\nSubmission Preview:\")\n",
    "print(submission_df.head())\n",
    "\n",
    "# Optionally, export to CSV:\n",
    "submission_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
